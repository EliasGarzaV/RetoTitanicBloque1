# Reto equipo #4: Supervivencia en el Titanic

Este repositorio es parte de un proyecto centrado en el famoso conjunto de datos del Titanic, que se encuentra disponible en Kaggle en la siguiente ubicaciÃ³n: [https://www.kaggle.com/competitions/titanic/](https://www.kaggle.com/competitions/titanic/). El objetivo principal de este proyecto es llevar a cabo un anÃ¡lisis exhaustivo del conjunto de datos del Titanic, realizar la limpieza y transformaciÃ³n de variables necesarias y desarrollar modelos de machine learning para predecir quiÃ©nes sobreviven y quiÃ©nes no.

## DescripciÃ³n del Proyecto

### Limpieza y TransformaciÃ³n de Variables

El primer paso en este proyecto es llevar a cabo una limpieza y transformaciÃ³n exhaustiva de los datos del Titanic. Esto implica tratar los valores faltantes, detectar y manejar valores atÃ­picos, y realizar una ingenierÃ­a de caracterÃ­sticas para preparar los datos para su uso en modelos de machine learning.

### Modelos de Machine Learning

Se desarrollan cuatro modelos de machine learning distintos para abordar el problema de clasificaciÃ³n de supervivencia en el Titanic:

1. **Logistic Regression**: Se utiliza una regresiÃ³n logÃ­stica como un modelo de referencia para la clasificaciÃ³n.

2. **Naive Bayes**: Se implementa el algoritmo de Naive Bayes como una alternativa de clasificaciÃ³n.

3. **Random Forest**: Se utiliza un modelo de Random Forest para aprovechar la capacidad de ensemble learning.

4. **Support Vector Machine**: Se aplica un Support Vector Machine (SVM) para explorar otro enfoque de clasificaciÃ³n.

### SelecciÃ³n del Modelo

DespuÃ©s de entrenar y evaluar los cuatro modelos, se selecciona el modelo de Random Forest con una profundidad mÃ¡xima de 9 debido a su alto rendimiento, con un accuracy de 0.85 en la predicciÃ³n de supervivencia.

### RegularizaciÃ³n y OptimizaciÃ³n de ParÃ¡metros

Se realiza un proceso de regularizaciÃ³n y optimizaciÃ³n de parÃ¡metros para mejorar la precisiÃ³n del modelo seleccionado y evitar el sobreajuste.

### Interfaz GrÃ¡fica

El proyecto culmina con la creaciÃ³n de una interfaz grÃ¡fica que permite a los usuarios ingresar datos de pasajeros del Titanic y obtener una predicciÃ³n de supervivencia utilizando el modelo de Random Forest optimizado.

## Estructura del Repositorio

- **data**: Contiene el conjunto de datos original del Titanic descargado desde Kaggle.
- **notebooks**: Contiene Jupyter Notebooks que detallan el proceso de limpieza, transformaciÃ³n de variables, entrenamiento de modelos y optimizaciÃ³n.
- **scripts**: Contiene scripts necesarios para el procesamiento de datos y la creaciÃ³n de la interfaz grÃ¡fica.
- **models**: Almacena los modelos entrenados y los archivos de optimizaciÃ³n.
- **webapp**: Contiene todos los archivos relacionados con la interfaz grÃ¡fica del usuario.

## Links a archivos de los entregables (Las cosas importantes):

- [Entregable 1: 14/08/2023](Pipe/DataCleansing.ipynb) - Limpieza y transformaciÃ³n de datos. Path: `Pipe/DataCleansing.ipynb`. Los resultados de la limpieza se guardan en `Data/train_clean.csv`.
- [Entregable 2: 28/08/2023](Model/resultados_modelos.ipynb) - Notebook con las pruebas de modelos hechas y con su comparaciÃ³n. 
- [Entregable 3: 04/09/2023](Model/ModeloMejorado.ipynb) - Reporte con el modelo refinado.
- **Revisa_competencias:** [Etregable Final con cÃ³digo: 13/09/2023](Entrega_Final/Codigo_Final.ipynb) - Reporte con cÃ³digo final. En el se recopilan las 3 entregas anteriores y se realizan las correcciones solicitadas. 
- **Revisa_competencias:** [Entregable Final Reporte: 13/09/2023](Entrega_Final/Reporte_Final_Titanic_Equipo_4.pdf)
- **Revisa_competencias :** [Interfaz grÃ¡fica: 13/09/2023](Interface/Home.py)

## Â¿CÃ³mo esta organizado nuestro repositorio?
Nuestro arbol de archivos se ve como sigue:
```
ğŸ“¦RetoTitanicBloque1
 â”£ ğŸ“‚Data
 â”ƒ â”£ ğŸ“œtest.csv
 â”ƒ â”£ ğŸ“œtrain.csv
 â”ƒ â”— ğŸ“œtrain_clean.csv
 â”£ ğŸ“‚Interface
 â”ƒ â”£ ğŸ“‚figures
 â”ƒ â”ƒ â”£ ğŸ“œ.gitkeep
 â”ƒ â”ƒ â”£ ğŸ“œDALLÂ·E 2023-08-28 10.39.13 - ship sinking minimalistic color logo.png
 â”ƒ â”ƒ â”£ ğŸ“œjack.jpeg
 â”ƒ â”ƒ â”£ ğŸ“œJackSwim.gif
 â”ƒ â”ƒ â”£ ğŸ“œjackWater.jpeg
 â”ƒ â”ƒ â”£ ğŸ“œlogo.png
 â”ƒ â”ƒ â”— ğŸ“œrose.png
 â”ƒ â”£ ğŸ“œ.gitkeep
 â”ƒ â”£ ğŸ“œHome.py
 â”ƒ â”— ğŸ“œmodel.pkl
 â”£ ğŸ“‚Model
 â”ƒ â”£ ğŸ“‚__pycache__
 â”ƒ â”ƒ â”£ ğŸ“œGaussianNB.cpython-311.pyc
 â”ƒ â”ƒ â”£ ğŸ“œGaussianNB.cpython-39.pyc
 â”ƒ â”ƒ â”£ ğŸ“œlogistic.cpython-39.pyc
 â”ƒ â”ƒ â”£ ğŸ“œRandom_Forest.cpython-311.pyc
 â”ƒ â”ƒ â”£ ğŸ“œRandom_Forest.cpython-39.pyc
 â”ƒ â”ƒ â”£ ğŸ“œSVM_titanic.cpython-311.pyc
 â”ƒ â”ƒ â”— ğŸ“œSVM_titanic.cpython-39.pyc
 â”ƒ â”£ ğŸ“œ.gitkeep
 â”ƒ â”£ ğŸ“œGaussianNB.ipynb
 â”ƒ â”£ ğŸ“œGaussianNB.py
 â”ƒ â”£ ğŸ“œlogistic.py
 â”ƒ â”£ ğŸ“œLogisticRegression.ipynb
 â”ƒ â”£ ğŸ“œRandom_Forest.py
 â”ƒ â”£ ğŸ“œresultados_modelos.ipynb
 â”ƒ â”— ğŸ“œSVM_titanic.py
 â”£ ğŸ“‚Pipe
 â”ƒ â”£ ğŸ“œ.gitkeep
 â”ƒ â”£ ğŸ“œcleaning_funcs.py
 â”ƒ â”— ğŸ“œDataCleansing.ipynb
 â”£ ğŸ“‚Results
 â”ƒ â”£ ğŸ“œLR_gender_submission.csv
 â”ƒ â”— ğŸ“œRandomForest_gender_submission.csv
 â”£ ğŸ“‚Testing
 â”ƒ â”£ ğŸ“œpruebas_ana.ipynb
 â”ƒ â”£ ğŸ“œpruebas_diego.ipynb
 â”ƒ â”£ ğŸ“œpruebas_elias.ipynb
 â”ƒ â”— ğŸ“œpruebas_romo.ipynb
 â”£ ğŸ“œ.gitignore
 â”— ğŸ“œREADME.md
```
En las cuales lo que hay en cada caso es:
 - `Data`: Los datos en crudo. principalmente en .csv
 - `Interface`: AquÃ­ estara todo lo que programemos de la interfaz grÃ¡fica.
 - `Model`: Todos nuestros scripts de modelos funcionando asi como el notebook con el segundo entregable.
 - `Pipe`: Las funciones de transformaciÃ³n que llevan los datos crudos a los inputs en el modelo. Aqui esta el primer entregable como jupyter y tambien tenemos las funciones para repetir esto facilmente con otros datos.
 - `Testing`: Aqui guardaremos nuestro playground. Hay notebooks en sucio en los que hacemos pruebas varias y no debe de haber entregables en esta carpeta.


## Correcciones en el entregable final respecto a las retroalimentaciones
- **Entregable 1: 14/08/2023** - Limpieza y transformaciÃ³n de datos: Se cambiÃ³ la tÃ©cnica usada para rellenar valores nulos de la variable **Age** como lo indicÃ³ el profesor en la retroalimentaciÃ³n.
- **Entregable 2: 28/08/2023** - Se agregÃ³ una descripciÃ³n de los modelos utilizados en el readme. Se agregÃ³ una descripciÃ³n (nombre y URL) del dataset utilizado. Se agregÃ³ la secciÃ³n de correcciones. Se incluye el enlace donde se puede descargar la base de datos en el reporte. Se hace una descripcion de las variables en crudo y despuÃ©s de ser procesadas. Se incluye descripcion del problema claramente. Se modifican hiperparametros en cada modelo y se explica por quÃ©. Se incluye secciÃ³n donde se explica las metricas a usar para comparar y como se separa en train y test. Se corrigen errores ortogrÃ¡ficos y datos faltantes en el reporte. Se incluye interpretacion de la comparativa de resultados.
- **Entregable 3: 04/09/2023** - El reporte ahora incluye claramente la separaciÃ³n del dataset en entrenamiento, validaciÃ³n, y prueba. Se incluye la metodologÃ­a a seguir al inicio de cada secciÃ³n. Se incluye cuÃ¡les mÃ©tricas de desempeÃ±o se van a usar y quÃ© hiper-parÃ¡metros van a variar. Se mejorÃ³ la interpretaciÃ³n de los resultados con un anÃ¡lisis mÃ¡s profundo. Se incluyen pruebas relacionadas con el efecto de regularizacion (optimizacion de parametros en el caso de un random forest) para interpretar sesgo y varianza.


Este proyecto tiene como objetivo proporcionar una comprensiÃ³n completa de cÃ³mo se pueden aplicar tÃ©cnicas de limpieza de datos y machine learning a un conjunto de datos real como el del Titanic, y cÃ³mo se puede implementar una interfaz grÃ¡fica para hacer predicciones basadas en el modelo entrenado. Â¡Disfrute explorando y aprendiendo!